{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 - Google Cloud Speech-to-Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein as Lev\n",
    "import io\n",
    "import os\n",
    "\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognize Function\n",
    "Uses Google's API to generate text from wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_recognize(audio_name,auth_key):\n",
    "\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=auth_key\n",
    "\n",
    "    # Instantiates a client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # The name of the audio file to transcribe\n",
    "    file_name = audio_name\n",
    "\n",
    "    # Loads the audio into memory\n",
    "    with io.open(file_name, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "        audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code='en-US')\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    response = client.recognize(config, audio)\n",
    "    for result in response.results:\n",
    "        return result.alternatives[0].transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Error Rate\n",
    "WER is computed by dividing the sum of substitutions, deletions and insertions by the total number words.  \n",
    "We can use Levenshtein distance to calculate the WER between two sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer(s1, s2):\n",
    "\n",
    "    s1 =s1.lower()\n",
    "    s2 =s2.lower()\n",
    "    b = set(s1.lower().split() + s2.lower().split())\n",
    "    \n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "\n",
    "    w1 = [chr(word2char[w]) for w in s1.split()]\n",
    "    w2 = [chr(word2char[w]) for w in s2.split()]\n",
    "    return Lev.distance(''.join(w1), ''.join(w2))/float(len(s2.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"./TIMIT_full/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = sorted(os.listdir(test_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to Google's API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"b659tutorial-259123-a3daa20bf890.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Real Sentence\n",
    "This function is used to get the original transcript of the wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_sen(path):\n",
    "    file = open(path+'.txt')\n",
    "    for line in file:\n",
    "        line = line.split(' ')\n",
    "        return ' '.join(line[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate WER for all Sentences in the TIMIT test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n"
     ]
    }
   ],
   "source": [
    "wer_all = []\n",
    "count = 0\n",
    "for d in d_list:\n",
    "    person_list = sorted(os.listdir(test_path+d+'/'))\n",
    "    for person in person_list:\n",
    "        new_path = test_path+d+'/'+person + '/'\n",
    "        files = sorted(os.listdir(new_path))\n",
    "        for file in files:\n",
    "            fname, ext = file.split('.')\n",
    "            if ext == 'wav':\n",
    "                count += 1\n",
    "                if count % 100 == 0:\n",
    "                    print(count)\n",
    "                \n",
    "                audio = new_path + '/' + fname\n",
    "                pred_sen = google_recognize(audio+'.wav',key)+'.'\n",
    "                real_sen = get_real_sen(audio)\n",
    "                wer_all.append(wer(pred_sen, real_sen)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Standard Deviation of WER on TIMIT Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1218402405384106\n",
      "0.16213492486584333\n"
     ]
    }
   ],
   "source": [
    "wer_np = np.array(wer_all)\n",
    "mean = wer_np.mean()\n",
    "std = wer_np.std()\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision Google Cloud Speech-to-Text API v/s Kaldi (Traditional ASR)\n",
    "Google Cloud Speech-to-Text API perfoms much better than Kaldi's Traditional ASR models. Kaldi's Best Models SGMM2 and SGMM2 + SMI had WER ~19.3 where as mean WER of Google Cloud is ~12.2 (0.122x100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things I noticed\n",
    "Google Cloud Speech-to-Text API doesn't add a Full Stop in the end of the sentence if it just has to predict one sentence. This originally made the mean WER and std WER worse (23.2 and 15.7 respectively). So I add a full stop in the transcription predicted by the API to improve the WER.  \n",
    "\n",
    "I assume Google's API does this to improve performance of it's Voice Assistants as usually they just recieve one sentence commands so to add a full stop and then remove it for knowledge extraction would be a waste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sndfl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train File to be used as noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_path = './TIMIT_full/train/dr1/fcjf0/sa1.wav'\n",
    "noise, sr = sndfl.read(noise_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desired SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsnr = [-5, 0, 10, 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists to store WERs respective to Desired SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_5 = []\n",
    "wer_0 = []\n",
    "wer_10 = []\n",
    "wer_25 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Noisy\n",
    "This function uses the clean signal, noise signal and desired SNR value to generate noisy signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy(signal, noise, dsnr):\n",
    "\n",
    "    while len(noise) < len(signal):\n",
    "        noise = np.hstack([noise, noise])\n",
    "    noise = noise[:len(signal)]\n",
    "\n",
    "    b_square = np.sum(np.square(signal))/np.sum(np.square(noise))\n",
    "    b_square = b_square/(10**(dsnr/10))\n",
    "    b = np.sqrt(b_square)\n",
    "    noisy = signal + b*noise\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temp Path to store the noisy signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = test_path + 'temp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate WER for all Signals in the TIMIT test data\n",
    "For each clean signal I generate 4 Noisy Signal with dSNR = -5, 0, 10 and 25. Then I use Google's API to predict the text transciptions on each of the noisy signals. Then I calculate the WER and append each WER to it's respective list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for d in d_list:\n",
    "    person_list = sorted(os.listdir(test_path+d+'/'))\n",
    "    for person in person_list:\n",
    "        new_path = test_path+d+'/'+person + '/'\n",
    "        \n",
    "        files = sorted(os.listdir(new_path))\n",
    "        for file in files:\n",
    "            fname, ext = file.split('.')\n",
    "            if ext == 'wav':\n",
    "                count += 1\n",
    "                if count % 50 == 0:\n",
    "                    print(count)\n",
    "                    \n",
    "                audio = new_path + '/' + fname\n",
    "                real_sen = get_real_sen(audio)\n",
    "                clean_signal, sr = sndfl.read(audio+'.wav')\n",
    "                \n",
    "                for d2 in dsnr:\n",
    "                    noisy_signal = generate_noisy(clean_signal, noise, d2)\n",
    "                    noisy_path = temp_path + fname + \"_\" + str(d2) + '.wav' \n",
    "                    sndfl.write(noisy_path, noisy_signal, sr)\n",
    "                    pred_sen = google_recognize(noisy_path, key)\n",
    "                    if pred_sen == None:\n",
    "                        pred_sen = \"\"\n",
    "                    else:\n",
    "                        pred_sen += '.'\n",
    "                    result = wer(pred_sen, real_sen)\n",
    "                    \n",
    "                    if d2 == -5:\n",
    "                        wer_5.append(result)\n",
    "                    elif d2 == 0:\n",
    "                        wer_0.append(result)\n",
    "                    elif d2 == 10:\n",
    "                        wer_10.append(result)\n",
    "                    else:\n",
    "                        wer_25.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting List to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_5_np = np.array(wer_5)\n",
    "wer_0_np = np.array(wer_0)\n",
    "wer_10_np = np.array(wer_10)\n",
    "wer_25_np = np.array(wer_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Standard Devations of WERs for all Desired SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For -5 db SNR signals, \n",
      " Mean WER = 1.0858575080673294 Standard Deviation = 0.3595471852656777\n"
     ]
    }
   ],
   "source": [
    "mean = wer_5_np.mean()\n",
    "std = wer_5_np.std()\n",
    "print(\"For -5 db SNR signals, \\n Mean WER = \" + str(mean) + \" Standard Deviation = \" + str(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 0 db SNR signals, \n",
      " Mean WER = 0.9084751703780346 Standard Deviation = 0.3000168169901338\n"
     ]
    }
   ],
   "source": [
    "mean = wer_0_np.mean()\n",
    "std = wer_0_np.std()\n",
    "print(\"For 0 db SNR signals, \\n Mean WER = \" + str(mean) + \" Standard Deviation = \" + str(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10 db SNR signals, \n",
      " Mean WER = 0.21941584869441266 Standard Deviation = 0.2568347970989601\n"
     ]
    }
   ],
   "source": [
    "mean = wer_10_np.mean()\n",
    "std = wer_10_np.std()\n",
    "print(\"For 10 db SNR signals, \\n Mean WER = \" + str(mean) + \" Standard Deviation = \" + str(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 25 db SNR signals, \n",
      " Mean WER = 0.12538260887505803 Standard Deviation = 0.16328324974300254\n"
     ]
    }
   ],
   "source": [
    "mean = wer_25_np.mean()\n",
    "std = wer_25_np.std()\n",
    "print(\"For 25 db SNR signals, \\n Mean WER = \" + str(mean) + \" Standard Deviation = \" + str(std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "As SNR decreases the performance decreases (or Mean WER increases).\n",
    "For the SNR values -5 and 0 the power of noise is comparable to the power of Speech. Therefore, we get such a high mean WER for them (108.59 for -5db and 90.85 for 0db). Also, on hearing these noisy samples we can notice that the speech of the two speakers intermingle and it is difficult to deduce what each person is saying.\n",
    "\n",
    "For 10 db signals we get Mean WER comparable to results of KALDI.  On hearing these signals we can notice that it takes a little effort to ignore the noise signal. Kaldi's Best Models SGMM2 and SGMM2 + SMI had WER ~19.3 and for 10db we get Mean WER ~21.9\n",
    "\n",
    "Whereas, for 25db signals the Mean WER is comparable to the results we got in part 1 (signals without any noise). For 25db signals the mean WER is 12.53 and for clean signals the WER is 12.18. On hearing the 25db signals we can notice that the noise signal is almost inaudible and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, as the SNR decreases the Standard Deviation also increases. As we know the Standard deviation tells us how members of a group are spread out from the mean value. Therefore it is safe to say that for High SNR all the WER are near to the mean (they do not vary too much) and for low SNR and WER is highly varied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
